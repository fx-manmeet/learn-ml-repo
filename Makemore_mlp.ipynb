{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMJdFcSlTUgjJLlhegT2bm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fx-manmeet/learn-ml-repo/blob/main/Makemore_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Solution to bigram model\n",
        "\n",
        "It takes context into consideration\n",
        "\n",
        "Eg,\n",
        "\n",
        "The cat is walking in the bedroom\n",
        "\n",
        "\n",
        "\n",
        "* A dog was running in a room\n",
        "\n",
        "* The cat is running in a room\n",
        "\n",
        "* A dog is walking in a bedroom\n",
        "\n",
        "* The dog was walking in the room"
      ],
      "metadata": {
        "id": "QKwx9NALRZti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xToAMGBRTeI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSQC9F8nTEbO",
        "outputId": "51054cdf-556e-4d83-8345-b1de83b7f312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-10 09:16:56--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-06-10 09:16:56 (4.34 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS7KsiafTGzF",
        "outputId": "05830d68-f87a-4e6a-df18-3ce8eecb67c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tlQ1wbNTI_O",
        "outputId": "45143d47-f9f0-4c57-c644-b845a6f08ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab of the character, and to/from conversion\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsVtU8-HTO1u",
        "outputId": "77954b04-679e-4763-a2b3-38ce74807062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build dataset\n",
        "\n",
        "block_size = 3  #context length\n",
        "\n",
        "X, Y = [], []\n",
        "for w in words[:5]:\n",
        "\n",
        "  print(w)\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    context = context[1:] + [ix] # crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NROCSch8T2ug",
        "outputId": "e3dbcbdc-634d-4f31-9ee5-8ef1e434f4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2))"
      ],
      "metadata": {
        "id": "mqfcsriyVTyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgvkNgFaVuGy",
        "outputId": "06cc0f25-0cd2-4d4e-9e95-f00b6c46e218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.6612,  1.2760])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(torch.tensor(5),num_classes= 27).float() @ C   # will mask others and give 5th indexed vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df-Ezh58WT9T",
        "outputId": "00d1aed8-a1a4-44b6-daa5-c222a2f0d6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.6612,  1.2760])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]"
      ],
      "metadata": {
        "id": "e4EP7ZAgWhCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoo-j9-_YMAJ",
        "outputId": "f5ba650a-18ee-4010-afc8-2d6867708548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = torch.randn((6,100))\n",
        "b1 = torch.randn(100)"
      ],
      "metadata": {
        "id": "Y7LMf5-7YOFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb[:,1,:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4uZ_pRdZaIc",
        "outputId": "c653ff0b-eada-47f7-9292-dd163adc6c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#works but torch has effecient way.\n",
        "torch.cat(torch.unbind(emb, dim=1),1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXgCGKmfav-P",
        "outputId": "9b02ba2b-7f7b-422d-b49d-607f877e6014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634, -1.6612,  1.2760],\n",
              "        [ 0.9228, -0.2634, -1.6612,  1.2760,  0.3906,  1.6046],\n",
              "        [-1.6612,  1.2760,  0.3906,  1.6046,  0.3906,  1.6046],\n",
              "        [ 0.3906,  1.6046,  0.3906,  1.6046,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634, -0.3990, -0.0548],\n",
              "        [ 0.9228, -0.2634, -0.3990, -0.0548, -0.3127,  1.0707],\n",
              "        [-0.3990, -0.0548, -0.3127,  1.0707, -0.2107,  0.6307],\n",
              "        [-0.3127,  1.0707, -0.2107,  0.6307,  0.8031,  1.1241],\n",
              "        [-0.2107,  0.6307,  0.8031,  1.1241, -0.2107,  0.6307],\n",
              "        [ 0.8031,  1.1241, -0.2107,  0.6307,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  1.7050,  1.4339,  0.8031,  1.1241],\n",
              "        [ 1.7050,  1.4339,  0.8031,  1.1241,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634, -0.2107,  0.6307],\n",
              "        [ 0.9228, -0.2634, -0.2107,  0.6307,  0.1522,  1.1814],\n",
              "        [-0.2107,  0.6307,  0.1522,  1.1814,  1.7050,  1.4339],\n",
              "        [ 0.1522,  1.1814,  1.7050,  1.4339, -1.1590, -0.5123],\n",
              "        [ 1.7050,  1.4339, -1.1590, -0.5123, -1.6612,  1.2760],\n",
              "        [-1.1590, -0.5123, -1.6612,  1.2760, -0.3127,  1.0707],\n",
              "        [-1.6612,  1.2760, -0.3127,  1.0707, -0.3127,  1.0707],\n",
              "        [-0.3127,  1.0707, -0.3127,  1.0707,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.1522,  1.1814],\n",
              "        [ 0.9228, -0.2634,  0.1522,  1.1814, -0.3990, -0.0548],\n",
              "        [ 0.1522,  1.1814, -0.3990, -0.0548, -1.6061, -0.0502],\n",
              "        [-0.3990, -0.0548, -1.6061, -0.0502,  0.6440, -0.7576],\n",
              "        [-1.6061, -0.0502,  0.6440, -0.7576, -0.2107,  0.6307],\n",
              "        [ 0.6440, -0.7576, -0.2107,  0.6307,  1.7050,  1.4339]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a =torch.arange(20)"
      ],
      "metadata": {
        "id": "SDFW13OWbfhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLypkjtJceEC",
        "outputId": "eb78ac6a-810d-4db2-b178-701cbd624abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view((2,5,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOtTS-NDcsa1",
        "outputId": "cc1cec47-213d-42e8-9369-f42cf1cc8981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1],\n",
              "         [ 2,  3],\n",
              "         [ 4,  5],\n",
              "         [ 6,  7],\n",
              "         [ 8,  9]],\n",
              "\n",
              "        [[10, 11],\n",
              "         [12, 13],\n",
              "         [14, 15],\n",
              "         [16, 17],\n",
              "         [18, 19]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every tensor in torch is stored in single dimension for computation\n",
        "a.storage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPcpiNTRcykv",
        "outputId": "c9e53e98-de69-45be-dbe1-e2f196caf337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-24ecd8ebaa08>:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  a.storage()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0\n",
              " 1\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5\n",
              " 6\n",
              " 7\n",
              " 8\n",
              " 9\n",
              " 10\n",
              " 11\n",
              " 12\n",
              " 13\n",
              " 14\n",
              " 15\n",
              " 16\n",
              " 17\n",
              " 18\n",
              " 19\n",
              "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 20]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#efficient\n",
        "emb.view((32,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOtrP-fkc90Y",
        "outputId": "4c045273-d03b-4c55-8c8e-d87dc5ac2cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634, -1.6612,  1.2760],\n",
              "        [ 0.9228, -0.2634, -1.6612,  1.2760,  0.3906,  1.6046],\n",
              "        [-1.6612,  1.2760,  0.3906,  1.6046,  0.3906,  1.6046],\n",
              "        [ 0.3906,  1.6046,  0.3906,  1.6046,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634, -0.3990, -0.0548],\n",
              "        [ 0.9228, -0.2634, -0.3990, -0.0548, -0.3127,  1.0707],\n",
              "        [-0.3990, -0.0548, -0.3127,  1.0707, -0.2107,  0.6307],\n",
              "        [-0.3127,  1.0707, -0.2107,  0.6307,  0.8031,  1.1241],\n",
              "        [-0.2107,  0.6307,  0.8031,  1.1241, -0.2107,  0.6307],\n",
              "        [ 0.8031,  1.1241, -0.2107,  0.6307,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  1.7050,  1.4339,  0.8031,  1.1241],\n",
              "        [ 1.7050,  1.4339,  0.8031,  1.1241,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634, -0.2107,  0.6307],\n",
              "        [ 0.9228, -0.2634, -0.2107,  0.6307,  0.1522,  1.1814],\n",
              "        [-0.2107,  0.6307,  0.1522,  1.1814,  1.7050,  1.4339],\n",
              "        [ 0.1522,  1.1814,  1.7050,  1.4339, -1.1590, -0.5123],\n",
              "        [ 1.7050,  1.4339, -1.1590, -0.5123, -1.6612,  1.2760],\n",
              "        [-1.1590, -0.5123, -1.6612,  1.2760, -0.3127,  1.0707],\n",
              "        [-1.6612,  1.2760, -0.3127,  1.0707, -0.3127,  1.0707],\n",
              "        [-0.3127,  1.0707, -0.3127,  1.0707,  1.7050,  1.4339],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.9228, -0.2634],\n",
              "        [ 0.9228, -0.2634,  0.9228, -0.2634,  0.1522,  1.1814],\n",
              "        [ 0.9228, -0.2634,  0.1522,  1.1814, -0.3990, -0.0548],\n",
              "        [ 0.1522,  1.1814, -0.3990, -0.0548, -1.6061, -0.0502],\n",
              "        [-0.3990, -0.0548, -1.6061, -0.0502,  0.6440, -0.7576],\n",
              "        [-1.6061, -0.0502,  0.6440, -0.7576, -0.2107,  0.6307],\n",
              "        [ 0.6440, -0.7576, -0.2107,  0.6307,  1.7050,  1.4339]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#so mul can work as\n",
        "h= torch.tanh(emb.view(emb.shape[0],6) @ W1 +b1)     #hidden state with tanh nonlinearity\n",
        "#h= emb.view(-1,6) @ W1 +b1               #works"
      ],
      "metadata": {
        "id": "fszQ9wnydcmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2fgAjSpd8R-",
        "outputId": "bec8c0c1-f1d3-49ca-e813-8661f893a456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn(100,27)\n",
        "b2 = torch.randn(27)"
      ],
      "metadata": {
        "id": "RvTJuOTXeI6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits= h @ W2 +b2"
      ],
      "metadata": {
        "id": "_eVYj6f3fuDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhFJZ5arf38_",
        "outputId": "c63e20c9-2d9b-4876-8ca9-8fffe0dd3568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()"
      ],
      "metadata": {
        "id": "e8sU3gBkf5VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob = counts / counts.sum(1, keepdim= True)"
      ],
      "metadata": {
        "id": "BibHmfqtgOdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNfaKR0EgaHc",
        "outputId": "9172aba2-bc44-4f3e-8acb-d28bb6ad94ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.8013e-16, 9.7014e-01, 3.6550e-08, 1.0382e-13, 2.1760e-14, 3.4425e-12,\n",
              "        5.5768e-06, 4.8400e-09, 3.5198e-14, 4.9310e-14, 1.9864e-05, 1.9878e-13,\n",
              "        1.2208e-16, 1.0618e-08, 2.8835e-12, 2.9545e-02, 5.9023e-09, 1.6186e-16,\n",
              "        7.2011e-13, 3.0234e-06, 9.9752e-09, 5.1508e-11, 1.1860e-11, 1.4439e-08,\n",
              "        2.9027e-04, 8.0061e-10, 3.7515e-14])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kg3UQxjgbE6",
        "outputId": "f0975bf0-2630-45bf-ec8e-ed47c578455f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss= -prob[torch.arange(32),Y].log().mean()"
      ],
      "metadata": {
        "id": "XOhnVTnyg7o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJ3h66vhM8X",
        "outputId": "3fc440f0-c445-4667-f4b8-b39782c3d477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.4380)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "S-ARpAy1hkQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4M_0IsqiLug",
        "outputId": "cf69ce85-8441-4875-e55e-e21704b863e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11897"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "8EfPVda0k0yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, X.shape[0], (32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[X[ix]] # (32, 3, 2)\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Y[ix])\n",
        "  #print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  #lr = lrs[i]\n",
        "  lr = 0.1 if i < 100000 else 0.01\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgkI8wg5icyV",
        "outputId": "9e27c4cc-617b-4018-ccd9-22f2f8b7ff71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9426345825195312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#revice it after a while\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "id": "A_UkQ1mbi3pV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2f1023-115f-4a67-b724-33c1933c403b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "olidikdixjyrnuxjn.\n",
            "olhinekkhgkbynrrhshrhrzothxjy.\n",
            "olhinekkaalddaddrzvwucovwtesjrhguyozvwucovwthslrhcewaejjrhguyozvwucovwthslrhcgfccamhjziyoaeijtyofvwolhinekkaadzdyxzvkhhjkrhcvyhclyikkoovwtesjrhguyrrhshrhrzothxjy.\n",
            "olhinekkaaxsyxshvwyhshrhrzovwthslrhcoyhshrhrzothxjy.\n",
            "olsikdixjy.\n",
            "olviuhjryhcoewikkogndrewaezjtyofvwolhinekkajdixjy.\n",
            "oliikkogndrewaezjtyofwikyojvwucovwthslrhcgfccamzjkkhgyekkoovwtesjrhguyozvwucovwthslrhxvkccyhguyozvwucovwthslrhxvymhjbyhigfy.\n",
            "olviuhjryhcaddrzvwucovwthslrhcgfjyrnuxjnhguyozvwucovwtesjrhguyozvwthslrhcadflhoewikyoaesza.\n",
            "olhinekkaadzdyxzvkhhjkrhxvymhjziyoaeijt.\n",
            "olxrhwaddrwuwdtesjrhguyozvwucovwixfkcovwtesjrhguyozvwucovwthslrhcgfccamhjziyoaeijt.\n",
            "oliikkoovwthslrtnxwjkfinouhm.\n",
            "olhinekkoovwtesjrhguyozvwucovwtesjrhguyozvwucovwtesjrhcgfccamhjziyoaeijt.\n",
            "olidikdixjyrnnxvymhjziyoaeijrhguyozvwucovwthsjkhgkbynrrhwvkshxjy.\n",
            "olxrngtesjrhgdiddaddrzvwucovwtesjrhgubdxshvwyhshrhrzothxjy.\n",
            "oliikkogndzxvkcckkhgkbynrrhshrhrzothxjy.\n",
            "olidikdixjy.\n",
            "ols.\n",
            "oliikkoovwtesjrhglbinekkoovwtesjrhguyozvwucovwthslrhcgfccamhjzigkoyndaddrzvwucovwthsjrhggkhynguhozwidikdixjkcynsrqhs.\n",
            "olidikdixjkcynhjdixjy.\n",
            "olxtnguhozwidtksjnhgubtxsjwhguyozvwucovwthslrhcgfccamhjziyoaeijthgfguxynzjtyojvwucovwtesjrhgigdyxzvkhhjkrhxvkccymgubt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MuTqsfrpbmiK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}